# AI 金融投資論文分析報告 (Pro Trader RL)
基於原始論文 `1-s2.0-S0957417424013319-main.pdf` 分析

## 1. 論文基本資訊
- **標題**: Pro Trader RL: Reinforcement learning framework for generating trading knowledge by mimicking the decision-making patterns of professional traders
- **作者**: Da Woon Jeong, Yeong Hyeon Gu (韓國世宗大學)
- **發表期刊**: Expert Systems With Applications (2024)

## 2. 系統核心概念
本論文提出 **Pro Trader RL** 架構，旨在模仿專業交易員的決策模式。不同於傳統 RL 直接優化獲利，此架構將交易過程拆解為模仿交易員思維的獨立模組。
- **核心哲學**: 學習「什麼情況下專業交易員會買入/賣出」，而非單純預測股價。
- **目標市場**: 美股 (S&P 500, MidCap 400, SmallCap 600)，共 1465 檔股票。

## 3. 系統架構 (System Architecture)
系統由四個主要模組組成：

### A. 資料預處理 (Data Preprocessing)
- **策略訊號**: 使用 **唐奇安通道 (Donchian Channel)** (20日高低點) 產生基礎買賣訊號，作為 RL 學習的樣本池。
- **變數生成**: 共 69 個變數，分為基礎、技術指標、大盤指數、個股vs大盤。
- **正規化 (Normalization)**: 提出 18 條特定的正規化公式，將不同價位的股票統一到相同尺度 (例如除以唐奇安通道上緣)。

### B. 買入知識 RL (Buy Knowledge RL)
- **目標**: 判斷「唐奇安通道發出的買入訊號」是否值得執行。
- **輸入**: 69 維正規化特徵。
- **網路結構**: DNN (69 -> 40 -> 2)。
- **演算法**: PPO (Proximal Policy Optimization)。
- **動作**: [Action 1: 高機率上漲, Action 2: 低機率上漲]。
- **獎勵機制 (基於 10% 門檻)**:
    - 定義 **成功交易** 為：未來回報率 $\ge$ 10%。
    - **Scenario 1**: 預測會漲 (Action 1) 且 實際漲 $\ge$ 10% $\rightarrow$ **+1 分**。
    - **Scenario 2**: 預測會漲 (Action 1) 但 實際漲 < 10% $\rightarrow$ **0 分**。
    - **Scenario 3**: 預測不漲 (Action 2) 且 實際漲 < 10% $\rightarrow$ **+1 分** (成功避雷)。
    - **Scenario 4**: 預測不漲 (Action 2) 但 實際漲 $\ge$ 10% $\rightarrow$ **0 分** (錯失機會)。

### C. 賣出知識 RL (Sell Knowledge RL)
- **目標**: 在買入後的 120 天內，每日判斷是否賣出。
- **輸入**: 70 維特徵 (69 維市場特徵 + 1 維 `SellReturn` (當前價格/買入價格))。
- **網路結構**: DNN (70 -> 40 -> 2)。
- **最佳賣點**: 當 (賣出機率 - 持有機率) > 0.85 時執行賣出。
- **獎勵機制 (基於相對排名)**:
    - 同樣以 10% 為成功門檻。
    - 若實際回報 $\ge$ 10%，獎勵根據其在所有成功案例中的**排名**給予 (最高 +2 分)。
    - 若預測賣出且實際回報 < 10% $\rightarrow$ **-1 分** (太早賣或虧損賣)。
    - 若預測持有且實際回報 < 10% $\rightarrow$ **+0.5 分** (正確持有等待)。

### D. 停損規則 (Stop Loss Rules)
彌補 RL 缺乏絕對風險控制的缺點，採用硬性規則：
1.  **急跌停損 (Stop Loss on Dips)**: 任何時候報酬率 < -10%，次日開盤強制賣出。
2.  **盤整停損 (Stop Loss on Sideways)**: 若 120 天內有連續 20 天報酬率都在 10% 以下，第 21 天強制賣出。

## 4. 實驗設定與結果
- **回測期間**: 2017/10/16 - 2023/10/15 (涵蓋多頭、空頭、盤整)。
- **資金設定**: 初始 $10,000，最多持倉 10 檔，每檔最多 10% 資金。
- **手續費**: 0.1%。
- **結果**: Pro Trader RL 年化報酬率 65.28%，夏普比率 4.58，MDD 8.37%，顯著優於大盤與其他 ML/DL 模型。

---

## 5. 論文 vs 您的程式碼 (`ptrl_TW50_optimized.py`) 差異分析

| 項目 | 原始論文 (Paper) | 您的程式碼 (Code) | 分析與建議 |
| :--- | :--- | :--- | :--- |
| **目標市場** | 美股 (S&P 1500) | 台股 (TW50 + 0050) | 台股波動性與美股不同，您的代碼已針對台股調整 (如 0050 當 Benchmark)。 |
| **獎勵函數** | **離散分類型** (+1, 0, -1)<br>基於是否超過 10% 門檻 | **連續數值型** (Return * 10)<br>直接最大化報酬率 | 論文的方法較像「分類問題」(會不會漲?)，您的代碼較像「回歸問題」(漲多少?)。論文方法可能在雜訊多的市場更穩定。 |
| **賣出邏輯** | (賣出機率 - 持有機率) > **0.85** | 模型直接輸出 Action 1 (賣出) | 論文設了 0.85 的高門檻，意味著非常有信心才賣，這能減少過度交易。 |
| **停損規則** | -10% 停損<br>20天漲不到 10% 停損 | -10% 停損<br>20天漲不到 **5%** 停損 | 您將盤整停損門檻從 10% 降至 5%，這對台股較合理的 (台股漲跌幅限制較小，波動可能較小)。 |
| **網路結構** | 自定義 DNN (3層) | 使用 Stable-Baselines3 預設 (通常是 MLP) | SB3 預設結構通常足夠強大，這點差異影響不大。 |
| **特徵工程** | 69 個變數 (包含大量 Index 比較) | 精簡版變數 (移除部分美股 Index 變數) | 您的代碼移除了 DJI 等美股指數變數，這是正確的，但建議加入台股大盤 (^TWII) 的相對強弱指標。 |

### 總結
您的程式碼是論文概念的**高度還原與在地化優化版本**。
- **優點**: 改用連續獎勵函數可能讓模型更積極追求高報酬；針對台股特性調整了停損門檻。
- **潛在改進**: 可以嘗試論文的「離散獎勵機制」(設 10% 門檻)，看看是否能降低回撤 (MDD)。論文方法傾向於「穩贏才出手」，您的代碼可能更傾向於「有賺就拼」。
