# -*- coding: utf-8 -*-
"""PTRL 50權值股 v02 - 台股特性優化版.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kyy5FgS5pFacFb1BqhlHi_lH0TQFabKd
"""

# @title 1. 環境設定與掛載 Google Drive
import os
from google.colab import drive

# 1. 掛載 Google Drive
drive.mount('/content/drive')

# 2. 定義儲存路徑
PROJECT_PATH = '/content/drive/MyDrive/ProTraderRL_TW50_Portfolio'
MODELS_PATH = os.path.join(PROJECT_PATH, 'models')
RESULTS_PATH = os.path.join(PROJECT_PATH, 'results')

for path in [MODELS_PATH, RESULTS_PATH]:
    if not os.path.exists(path):
        os.makedirs(path)
        print(f"已建立資料夾: {path}")
    else:
        print(f"資料夾已存在: {path}")

# 3. 安裝必要套件
print("正在安裝必要套件...")
!pip install stable-baselines3[extra] yfinance pandas_ta gymnasium matplotlib shimmy>=0.2.1 -q
print("安裝完成。")

# @title 2. 下載台灣 50 大權值股資料
import yfinance as yf
import pandas as pd
import numpy as np
from tqdm import tqdm

def fetch_tw50_data(start_date="2010-01-01"):
    # 台灣市值前 50 大股票代號 (0050成分股) + 0050ETF本身(當基準) + 大盤指數
    tickers = [
        "0050.TW", "^TWII", # 基準與大盤
        # 台積電, 鴻海, 聯發科, 富邦金, 廣達, 台達電, 國泰金, 中華電, 中信金, 日月光...
        "2330.TW", "2317.TW", "2454.TW", "2881.TW", "2382.TW", "2308.TW", "2882.TW", "2412.TW", "2891.TW", "3711.TW",
        "2886.TW", "2884.TW", "2303.TW", "2885.TW", "3231.TW", "3034.TW", "5880.TW", "2892.TW", "3008.TW", "2357.TW",
        "2002.TW", "2890.TW", "1101.TW", "2880.TW", "2883.TW", "2887.TW", "2345.TW", "3045.TW", "5871.TW", "3037.TW",
        "2912.TW", "1216.TW", "6505.TW", "4938.TW", "5876.TW", "1303.TW", "2395.TW", "2379.TW", "1301.TW", "3017.TW",
        "1326.TW", "2603.TW", "1590.TW", "3661.TW", "2327.TW", "4904.TW", "2801.TW", "1605.TW", "1504.TW", "2207.TW"
    ]

    print(f"開始下載 {len(tickers)} 檔標的資料...")
    # 使用 threads 加速下載
    data = yf.download(tickers, start=start_date, group_by='ticker', auto_adjust=True, threads=True, progress=False)

    clean_data = {}
    market_index = None

    # 處理大盤指數
    if "^TWII" in data.columns.levels[0]:
        market_index = data["^TWII"].copy()
        if isinstance(market_index.columns, pd.MultiIndex):
            market_index.columns = market_index.columns.get_level_values(0)
        clean_data["^TWII"] = market_index

    # 處理個股
    print("正在整理數據...")
    for t in tqdm(tickers):
        if t == "^TWII": continue
        try:
            df = data[t].copy()
            # 處理 yfinance 多層索引
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)

            # 欄位重新命名確保一致
            df = df.rename(columns={"Open": "Open", "High": "High", "Low": "Low", "Close": "Close", "Volume": "Volume"})

            # 移除空值與資料過少的股票
            df = df.dropna()
            if len(df) > 250: # 至少要有一年的資料
                clean_data[t] = df
        except Exception as e:
            print(f"Skipping {t}: {e}")

    print(f"資料處理完成，共 {len(clean_data)} 檔有效資料。")
    return clean_data, clean_data.get("^TWII")

raw_data_dict, market_index_df = fetch_tw50_data()

# @title 3. 特徵工程 (最終修正版：修復語法與除零風險)
import pandas_ta as ta
import pandas as pd
import numpy as np

FEATURE_COLS = [
    # 1. 價格類 (相對於 DC_Upper 的比例)
    'Norm_Close', 'Norm_Open', 'Norm_High', 'Norm_Low',
    'Norm_DC_Lower',
    'Norm_HA_Open', 'Norm_HA_High', 'Norm_HA_Low', 'Norm_HA_Close',
    'Norm_SuperTrend_1', 'Norm_SuperTrend_2',

    # 2. 震盪指標類 (0~1)
    'Norm_RSI', 'Norm_MFI',

    # 3. 波動率類 (變動率 或 相對比例)
    'Norm_ATR_Change',  # 論文 Eq.10: ATR(t) / ATR(t-1)

    # 4. 相對強弱類 (Min-Max Scaling 或 原始比率)
    'Norm_RS_Ratio',
    'RS_ROC_5', 'RS_ROC_10', 'RS_ROC_20', 'RS_ROC_60', 'RS_ROC_120'
]

def calculate_features(df_in, benchmark_df):
    df = df_in.copy()

    # --- 1. 計算原始指標 (Raw Indicators) ---

    # Donchian Channel (20日 - 正規化基準)
    df['DC_Upper'] = df['High'].rolling(20).max().shift(1)
    df['DC_Lower'] = df['Low'].rolling(20).min().shift(1)

    # Donchian Channel (10日 - 買入訊號用)
    df['DC_Upper_10'] = df['High'].rolling(10).max().shift(1)

    # 填補空值
    df['DC_Upper'] = df['DC_Upper'].fillna(method='bfill')
    df['DC_Lower'] = df['DC_Lower'].fillna(method='bfill')
    df['DC_Upper_10'] = df['DC_Upper_10'].fillna(method='bfill')

    # 基礎指標
    df['ATR'] = ta.atr(df['High'], df['Low'], df['Close'], length=10)
    df['RSI'] = ta.rsi(df['Close'], length=14)
    try:
        df['MFI'] = ta.mfi(df['High'], df['Low'], df['Close'], df['Volume'], length=14)
    except:
        df['MFI'] = 50.0

    # Heikin Ashi
    ha = ta.ha(df['Open'], df['High'], df['Low'], df['Close'])
    df['HA_Open'] = ha['HA_open']
    df['HA_High'] = ha['HA_high']
    df['HA_Low'] = ha['HA_low']
    df['HA_Close'] = ha['HA_close']

    # SuperTrend
    st1 = ta.supertrend(df['High'], df['Low'], df['Close'], length=14, multiplier=2.0)
    st2 = ta.supertrend(df['High'], df['Low'], df['Close'], length=21, multiplier=1.0)
    df['SuperTrend_1'] = st1[st1.columns[0]]
    df['SuperTrend_2'] = st2[st2.columns[0]]

    # --- 2. 論文正規化邏輯 (Normalization) ---

    # [A] 價格類正規化：除以 DC_Upper (Eq. 1-8)
    # 修正：移除多餘的 replace，並確保分母安全
    base_price = df['DC_Upper'].replace(0, np.nan).fillna(method='bfill')

    price_cols = ['Close', 'Open', 'High', 'Low', 'DC_Lower',
                  'HA_Open', 'HA_High', 'HA_Low', 'HA_Close',
                  'SuperTrend_1', 'SuperTrend_2']

    for col in price_cols:
        df[f'Norm_{col}'] = df[col] / base_price

    # [B] 震盪指標正規化：除以 100
    df['Norm_RSI'] = df['RSI'] / 100.0
    df['Norm_MFI'] = df['MFI'] / 100.0

    # [C] 波動率正規化：變動率
    df['Norm_ATR_Change'] = (df['ATR'] / df['ATR'].shift(1)).fillna(1.0)

    # [D] 相對強弱 RS 正規化
    if benchmark_df is not None:
        bench_close = benchmark_df['Close'].reindex(df.index).fillna(method='ffill')

        # RS 原始值
        df['RS_Raw'] = df['Close'] / bench_close

        # Min-Max Scaling (12個月窗口)
        rs_min = df['RS_Raw'].rolling(250).min()
        rs_max = df['RS_Raw'].rolling(250).max()

        # 修正：加上 1e-9 避免分母為 0，並預填補 1.0
        denominator = (rs_max - rs_min).replace(0, np.nan).fillna(1.0) + 1e-9
        df['Norm_RS_Ratio'] = (df['RS_Raw'] - rs_min) / denominator
        df['Norm_RS_Ratio'] = df['Norm_RS_Ratio'].fillna(0.5)

        # RS ROC
        for period in [5, 10, 20, 60, 120]:
            df[f'RS_ROC_{period}'] = df['RS_Raw'].pct_change(period).fillna(0)
    else:
        df['Norm_RS_Ratio'] = 0.0
        for period in [5, 10, 20, 60, 120]:
            df[f'RS_ROC_{period}'] = 0.0

    # --- 3. Label 與訊號 ---
    # 使用 10 日突破作為訊號 (較積極)
    df['Signal_Buy_Filter'] = (df['High'] > df['DC_Upper_10'])

    # Label: 未來 20 天最大漲幅
    df['Next_20d_Max'] = df['High'].shift(-20).rolling(20).max() / df['Close'] - 1

    return df.dropna()

print("正在計算特徵 (包含論文正規化邏輯 D - 修正版)...")
processed_data = {}
bench_df = raw_data_dict.get("^TWII")

for ticker, df in raw_data_dict.items():
    if ticker != "^TWII":
        try:
            processed_data[ticker] = calculate_features(df, bench_df)
        except Exception as e:
            print(f"Error processing {ticker}: {e}")

print(f"特徵工程完成。")

# @title 4. 定義 RL 環境 (修正版：解決失明與獎勵問題)
import numpy as np
import gymnasium as gym
from gymnasium import spaces

# 必須與 Step 3 產生的欄位一致
FEATURE_COLS = [
    'Norm_Close', 'Norm_Open', 'Norm_High', 'Norm_Low', 'Norm_DC_Lower',
    'Norm_HA_Open', 'Norm_HA_High', 'Norm_HA_Low', 'Norm_HA_Close',
    'Norm_SuperTrend_1', 'Norm_SuperTrend_2',
    'Norm_RSI', 'Norm_MFI',
    'Norm_ATR_Change',
    'Norm_RS_Ratio',
    'RS_ROC_5', 'RS_ROC_10', 'RS_ROC_20', 'RS_ROC_60', 'RS_ROC_120'
]

class BuyEnv(gym.Env):
    def __init__(self, data_dict, is_training=True):
        super().__init__()
        self.samples = []

        print("正在初始化 BuyEnv...")
        # 檢查欄位一致性
        sample_df = next(iter(data_dict.values()))
        missing = [c for c in FEATURE_COLS if c not in sample_df.columns]
        if missing:
            raise ValueError(f"Missing columns: {missing}")

        for t, df in data_dict.items():
            signals = df[df['Signal_Buy_Filter'] == True]
            if len(signals) > 0:
                states = signals[FEATURE_COLS].values.astype(np.float32)
                future_rets = signals['Next_20d_Max'].values.astype(np.float32)
                for i in range(len(signals)):
                    self.samples.append((states[i], future_rets[i]))

        print(f"BuyEnv 樣本數: {len(self.samples)}")
        self.action_space = spaces.Discrete(2) # 0: 觀望, 1: 買進
        self.observation_space = spaces.Box(-np.inf, np.inf, shape=(len(FEATURE_COLS),), dtype=np.float32)
        self.is_training = is_training
        self.idx = 0

    def reset(self, seed=None, options=None):
        if self.is_training:
            self.idx = np.random.randint(0, len(self.samples))
        else:
            self.idx = (self.idx + 1) % len(self.samples)
        return self.samples[self.idx][0], {}

    def step(self, action):
        _, max_ret = self.samples[self.idx]

        reward = 0

        if action == 1: # 買入
            # 連續獎勵：漲 1% 得 0.1，漲 5% 得 0.5
            reward = max_ret * 10.0

            # 大賠懲罰 (跌超過 5% 額外扣分)
            if max_ret < -0.05:
                reward -= 1.0

        else: # 觀望
            # 修改重點 1：降低後悔門檻 (從 5% 降到 2%)
            # 如果漲超過 2% 你沒買，就要開始扣分，而且是「連續扣分」
            if max_ret > 0.02:
                # 錯過越多，扣越多 (例如錯過 5% -> 扣 0.5)
                reward = -(max_ret * 10.0)

            # 修改重點 2：只有在「真的避開下跌」時才給獎勵
            elif max_ret < 0:
                reward = 0.1 # 成功避險

            # 修改重點 3：盤整時 (0% ~ 2%) 給 0 分，而不是 0.1
            else:
                reward = 0.0

        return self.samples[self.idx][0], reward, True, False, {}

class SellEnv(gym.Env):
    def __init__(self, data_dict):
        super().__init__()
        self.episodes = []

        print("正在初始化 SellEnv...")
        for t, df in data_dict.items():
            buy_indices = np.where(df['Signal_Buy_Filter'])[0]

            # 預先轉為 numpy 加速
            feature_data = df[FEATURE_COLS].values.astype(np.float32)
            close_prices = df['Close'].values.astype(np.float32)

            for idx in buy_indices:
                # 確保有未來 120 天資料
                if idx + 120 < len(df):
                    episode_features = feature_data[idx : idx+120]
                    episode_prices = close_prices[idx : idx+120]
                    # 計算波段最高價 (用於計算相對效率)
                    max_price = np.max(episode_prices)

                    self.episodes.append({
                        'features': episode_features,
                        'prices': episode_prices,
                        'max_price': max_price
                    })

        print(f"SellEnv 訓練路徑數: {len(self.episodes)}")
        self.action_space = spaces.Discrete(2) # 0: 持有, 1: 賣出

        # 觀測空間：市場特徵 + [當前報酬率, 持有時間比例]
        self.obs_dim = len(FEATURE_COLS) + 2
        self.observation_space = spaces.Box(-np.inf, np.inf, shape=(self.obs_dim,), dtype=np.float32)

    def reset(self, seed=None, options=None):
        self.current_episode = self.episodes[np.random.randint(0, len(self.episodes))]
        self.day = 0
        self.buy_price = self.current_episode['prices'][0]
        self.max_potential_price = self.current_episode['max_price']
        return self._get_observation(), {}

    def _get_observation(self):
        market_features = self.current_episode['features'][self.day]
        current_price = self.current_episode['prices'][self.day]

        current_return = current_price / self.buy_price
        time_ratio = self.day / 120.0

        obs = np.concatenate([market_features, [current_return, time_ratio]])
        return obs.astype(np.float32)

    def step(self, action):
        current_price = self.current_episode['prices'][self.day]
        current_return = current_price / self.buy_price

        reward = 0
        done = False

        # 1. 強制停損 (Risk Management)
        if current_return < 0.90:
            reward = -5.0 # 懲罰大賠
            done = True

        # 2. Agent 決定賣出
        elif action == 1:
            potential_profit = self.max_potential_price - self.buy_price
            actual_profit = current_price - self.buy_price

            # 情況 A: 是賺錢波段 (Max > Buy)
            if potential_profit > 0:
                # 效率 = 吃到的魚身比例
                efficiency = actual_profit / potential_profit
                # 獎勵效率 (0 ~ 1.0) * 加權
                reward = efficiency * 2.0

                # 如果賣在頭部 (>90% 效率)，給予重賞 [cite: 460-461]
                if efficiency > 0.9:
                    reward += 1.0

            # 情況 B: 買進後就一路跌 (爛牌局)
            else:
                # 少賠就是贏，賠越少扣分越少
                reward = (current_return - 1.0) * 5.0
                # 如果能在小賠 (<2%) 時跑掉，給予獎勵 (止損獎勵)
                if current_return > 0.98:
                    reward += 1.0

            done = True

        # 3. 時間到強制結算
        elif self.day >= 119:
            potential_profit = self.max_potential_price - self.buy_price
            actual_profit = current_price - self.buy_price

            if potential_profit > 0:
                reward = (actual_profit / potential_profit) * 2.0
            else:
                reward = (current_return - 1.0) * 5.0
            done = True

        # 4. 持有
        else:
            # 微小獎勵鼓勵獲利抱單 (Let profits run)
            if current_return > 1.02:
                reward = 0.02
            self.day += 1

        if not done:
            next_obs = self._get_observation()
        else:
            next_obs = self._get_observation()

        return next_obs, reward, done, False, {}

# @title 5. 增強版模型訓練 (防斷線機制：自動存檔與續練)
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList
import os
import glob

# 1. 確保目錄存在
if not os.path.exists(MODELS_PATH):
    os.makedirs(MODELS_PATH)

# 2. 準備環境
train_data = {k: v for k, v in processed_data.items() if k != "0050.TW"}
buy_env = BuyEnv(train_data, is_training=True)
sell_env = SellEnv(train_data)
eval_env = BuyEnv(train_data, is_training=True)

# 3. 設定參數 (對齊論文)
ppo_params = {
    "learning_rate": 0.0001,
    "n_steps": 2048,
    "batch_size": 64,
    # === 修改這裡 ===
    # 原本是 0.01，我們調高到 0.05 或 0.1
    # 這會強迫模型在訓練前期多方嘗試，不會太快變成 "死腦筋"
    "ent_coef": 0.05,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "vf_coef": 0.5,
    "verbose": 1
}

# === 防斷線機制核心 ===

# A. 設定檢查點 (Checkpoint)：每 50,000 步自動存檔一次
# 檔案會存在 Google Drive: .../models/ppo_buy_ckpt_50000_steps.zip
checkpoint_callback = CheckpointCallback(
    save_freq=50000,
    save_path=MODELS_PATH,
    name_prefix="ppo_buy_ckpt"
)

# B. 設定評估回調 (保留原本的 Best Model 機制)
eval_callback = EvalCallback(
    eval_env,
    best_model_save_path=os.path.join(MODELS_PATH, "best_buy_model"),
    log_path=RESULTS_PATH,
    eval_freq=20000,
    deterministic=True,
    render=False
)

# 將兩個回調函數串在一起
callbacks = CallbackList([checkpoint_callback, eval_callback])

# C. 自動偵測是否有「存檔」可以續練
def get_latest_checkpoint(path, prefix):
    # 搜尋目錄下所有 ppo_buy_ckpt_*.zip
    files = glob.glob(os.path.join(path, f"{prefix}_*_steps.zip"))
    if not files:
        return None
    # 找出步數最大 (最新) 的檔案
    latest_file = max(files, key=lambda x: int(x.split('_')[-2]))
    return latest_file

# 設定總目標步數
TOTAL_TIMESTEPS = 2000000

# --- Buy Agent 訓練邏輯 ---
print("\n=== 檢查 Buy Agent 存檔... ===")
latest_ckpt = get_latest_checkpoint(MODELS_PATH, "ppo_buy_ckpt")

if latest_ckpt:
    print(f"發現中斷的存檔：{latest_ckpt}")
    print("正在載入模型並繼續訓練...")
    # 載入舊模型 (注意：要傳入 env)
    buy_model = PPO.load(latest_ckpt, env=buy_env, **ppo_params)

    # 計算還剩下多少步要跑
    # 從檔名提取已跑步數，例如 ppo_buy_ckpt_500000_steps.zip
    current_steps = int(latest_ckpt.split('_')[-2])
    remaining_steps = max(0, TOTAL_TIMESTEPS - current_steps)

    if remaining_steps > 0:
        print(f"接續訓練剩餘步數: {remaining_steps}")
        # reset_num_timesteps=False 很重要，這樣 TensorBoard 的曲線才會接在一起
        buy_model.learn(total_timesteps=remaining_steps, callback=callbacks, reset_num_timesteps=False)
    else:
        print("此存檔已完成目標步數，跳過訓練。")
else:
    print("未發現存檔，開始重新訓練...")
    buy_model = PPO("MlpPolicy", buy_env, **ppo_params)
    buy_model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=callbacks)

# 儲存最終版本
buy_model.save(os.path.join(MODELS_PATH, "ppo_buy_tw50"))
print("Buy Agent 訓練階段完成。")


# --- Sell Agent 訓練邏輯 (同理) ---
# 為了簡化，Sell Agent 通常訓練較快，這裡示範簡單版，您也可以套用上面的邏輯
print("\n=== 開始訓練 Sell Agent ===")
sell_model = PPO("MlpPolicy", sell_env, **ppo_params)
sell_model.learn(total_timesteps=TOTAL_TIMESTEPS // 2)
sell_model.save(os.path.join(MODELS_PATH, "ppo_sell_tw50"))
print("Sell Agent 訓練完成。")

print(f"\n所有模型已安全儲存至 Google Drive: {MODELS_PATH}")

# @title 6. 投資組合回測 (Portfolio Backtest) - 修正版
import datetime
import pandas as pd
import numpy as np
from tqdm import tqdm
from stable_baselines3 import PPO
import os

class PortfolioBacktester:
    def __init__(self, data_dict, buy_model, sell_model, initial_capital=1000000):
        self.data_dict = data_dict
        self.buy_model = buy_model
        self.sell_model = sell_model
        self.cash = initial_capital
        self.inventory = {} # {ticker: {shares, cost_price, entry_date, days_held}}
        self.history = []
        self.max_positions = 10 # 論文設定：最多持倉 10 檔
        self.position_size_pct = 0.10 # 論文設定：每檔最多投入 10%

        # 建立時間軸 (取所有股票日期的交集，確保數據對齊)
        # 為了回測速度，我們取最近 3 年 (2021-2024)
        sample_ticker = list(data_dict.keys())[0]
        self.dates = sorted(data_dict[sample_ticker].index)
        self.dates = [d for d in self.dates if d >= pd.Timestamp('2021-01-01')]

    def run(self):
        print(f"開始回測... 期間: {self.dates[0].date()} 到 {self.dates[-1].date()}")

        for current_date in tqdm(self.dates):
            current_value = self.cash

            # --- 1. 檢查持倉 (Sell Logic) ---
            # 必須使用 list(keys) 因為我們會動態刪除
            for ticker in list(self.inventory.keys()):
                info = self.inventory[ticker]
                df = self.data_dict[ticker]

                if current_date not in df.index: continue

                # 取得當日數據 row
                row = df.loc[current_date]
                price = row['Close']

                # 計算當前價值 (用於部位控管計算)
                current_value += info['shares'] * price

                # 更新持有天數
                info['days_held'] += 1

                # === 修正點：構建與訓練環境一致的 Sell State ===
                # 1. 市場特徵
                market_features = row[FEATURE_COLS].values.astype(np.float32)
                # 2. 帳戶狀態
                ret = price / info['cost_price']
                time_ratio = info['days_held'] / 120.0

                # 3. 拼接 (Market Features + [Return, Time])
                sell_state = np.concatenate([market_features, [ret, time_ratio]])

                # 預測動作
                action, _ = self.sell_model.predict(sell_state, deterministic=True)

                # 賣出條件: 1. AI 賣出, 2. 停損 (-10%), 3. 盤整 (>20天沒漲)
                stop_loss = ret < 0.90
                time_stop = (info['days_held'] > 20) and (ret < 1.05)

                if action == 1 or stop_loss or time_stop:
                    # 執行賣出 (假設以當日收盤價賣出，扣 0.4% 稅費)
                    revenue = info['shares'] * price * (1 - 0.004)
                    self.cash += revenue
                    del self.inventory[ticker]

            # --- 2. 檢查買入 (Buy Logic) ---
            # 只有當持倉 < 10 且有現金時才檢查
            if len(self.inventory) < self.max_positions and self.cash > 10000:

                # 隨機打亂股票順序，避免每天都優先買台積電
                tickers = list(self.data_dict.keys())
                np.random.shuffle(tickers)

                for ticker in tickers:
                    if ticker == "^TWII" or ticker == "0050.TW": continue
                    if ticker in self.inventory: continue # 已持有

                    df = self.data_dict[ticker]
                    if current_date not in df.index: continue

                    row = df.loc[current_date]

                    # 論文濾網：唐奇安通道突破
                    if row['Signal_Buy_Filter']:
                        # 提取 Buy State
                        state = row[FEATURE_COLS].values.astype(np.float32)
                        action, _ = self.buy_model.predict(state, deterministic=True)

                        if action == 1:
                            # 執行買入
                            price = row['Close']
                            # 計算部位大小 (總資金的 10%)
                            total_asset = current_value # 近似值
                            target_amt = total_asset * self.position_size_pct

                            # 確保有足夠現金
                            invest_amt = min(target_amt, self.cash)

                            if invest_amt > price * 1000: # 至少買得起一張 (假設)
                                shares = int(invest_amt / price)
                                cost = shares * price * (1 + 0.001425) # 加手續費

                                self.cash -= cost
                                self.inventory[ticker] = {
                                    'shares': shares,
                                    'cost_price': price,
                                    'entry_date': current_date,
                                    'days_held': 0
                                }

                                if len(self.inventory) >= self.max_positions:
                                    break

            # 紀錄當日總資產
            equity = 0
            for t, info in self.inventory.items():
                if current_date in self.data_dict[t].index:
                    equity += info['shares'] * self.data_dict[t].loc[current_date]['Close']
                else:
                    # 若當日無報價(停牌)，用成本價估算
                    equity += info['shares'] * info['cost_price']

            total_value = self.cash + equity
            self.history.append({'Date': current_date, 'Portfolio_Value': total_value})

        return pd.DataFrame(self.history).set_index('Date')

# === 修正載入路徑：優先載入 Best Model ===
best_buy_path = os.path.join(MODELS_PATH, "best_buy_model", "best_model.zip")
final_buy_path = os.path.join(MODELS_PATH, "ppo_buy_tw50")

if os.path.exists(best_buy_path):
    print(f"✅ 載入最佳模型 (Best Model): {best_buy_path}")
    loaded_buy_model = PPO.load(best_buy_path)
else:
    print(f"⚠️ 找不到最佳模型，載入最終模型: {final_buy_path}")
    loaded_buy_model = PPO.load(final_buy_path)

# Sell Agent 通常較穩定，可以用最終版，或者您也可以為它設定 Best Model
loaded_sell_model = PPO.load(os.path.join(MODELS_PATH, "ppo_sell_tw50"))

# 執行回測 (只針對個股回測，不含指數)
stock_data_only = {k: v for k, v in processed_data.items() if k != "^TWII" and k != "0050.TW"}
backtester = PortfolioBacktester(stock_data_only, loaded_buy_model, loaded_sell_model)
portfolio_df = backtester.run()

print("\n回測完成！")
print(f"期初資金: {portfolio_df.iloc[0]['Portfolio_Value']:.0f}")
print(f"期末資金: {portfolio_df.iloc[-1]['Portfolio_Value']:.0f}")

# @title 7. 績效視覺化 (AI Portfolio vs 0050 Benchmark)
import matplotlib.pyplot as plt

# 準備 Benchmark 數據 (0050.TW)
benchmark_df = processed_data['0050.TW'].copy()
# 截取相同時間段
benchmark_df = benchmark_df.loc[portfolio_df.index[0]:portfolio_df.index[-1]]

# 正規化 (歸一化到 1.0 開始)
portfolio_nav = portfolio_df['Portfolio_Value'] / portfolio_df['Portfolio_Value'].iloc[0]
benchmark_nav = benchmark_df['Close'] / benchmark_df['Close'].iloc[0]

# 計算報酬率
ai_return = (portfolio_nav.iloc[-1] - 1) * 100
bench_return = (benchmark_nav.iloc[-1] - 1) * 100

plt.figure(figsize=(12, 6))
plt.plot(portfolio_nav.index, portfolio_nav, label=f'AI Portfolio (Return: {ai_return:.2f}%)', color='red', linewidth=2)
plt.plot(benchmark_nav.index, benchmark_nav, label=f'0050 Buy & Hold (Return: {bench_return:.2f}%)', color='gray', linestyle='--')

plt.title('Pro Trader RL Strategy (Top 50 Selection) vs 0050 ETF')
plt.xlabel('Date')
plt.ylabel('Normalized Value')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()

save_path = os.path.join(RESULTS_PATH, "comparison_chart_portfolio.png")
plt.savefig(save_path)
plt.show()

print(f"圖表已儲存至: {save_path}")

# @title 8. 進階分析：每年 AI 持股狀況與投入金額 - 修正版
import matplotlib.pyplot as plt
from collections import Counter
import pandas as pd
import numpy as np

# 定義一個能記錄詳細資訊的回測器
class DetailedBacktester:
    def __init__(self, data_dict, buy_model, sell_model, initial_capital=1000000):
        self.data_dict = data_dict
        self.buy_model = buy_model
        self.sell_model = sell_model
        self.cash = initial_capital
        self.inventory = {}
        self.max_positions = 10
        self.position_size_pct = 0.10

        # 設定回測時間 (2021-2024)
        sample_ticker = list(data_dict.keys())[0]
        self.dates = sorted(data_dict[sample_ticker].index)
        self.dates = [d for d in self.dates if d >= pd.Timestamp('2021-01-01')]

    def run(self):
        print(f"正在執行詳細回測分析 ({self.dates[0].date()} ~ {self.dates[-1].date()})...")
        records = []

        for current_date in self.dates:
            # 1. 賣出檢查
            for ticker in list(self.inventory.keys()):
                info = self.inventory[ticker]
                df = self.data_dict[ticker]
                if current_date not in df.index: continue

                row = df.loc[current_date]
                price = row['Close']
                info['days_held'] += 1

                # === 修正點：Sell State 構建 ===
                market_features = row[FEATURE_COLS].values.astype(np.float32)
                ret = price / info['cost_price']
                time_ratio = info['days_held'] / 120.0
                sell_state = np.concatenate([market_features, [ret, time_ratio]])

                action, _ = self.sell_model.predict(sell_state, deterministic=True)

                if action == 1 or ret < 0.90 or (info['days_held'] > 20 and ret < 1.05):
                    revenue = info['shares'] * price * (1 - 0.004)
                    self.cash += revenue
                    del self.inventory[ticker]

            # 2. 買入檢查
            # 估算當前權益 (Equity)
            current_equity = 0
            for t, info in self.inventory.items():
                if current_date in self.data_dict[t].index:
                    current_equity += info['shares'] * self.data_dict[t].loc[current_date]['Close']
                else:
                    current_equity += info['shares'] * info['cost_price']

            total_asset = self.cash + current_equity

            if len(self.inventory) < self.max_positions and self.cash > 10000:
                tickers = list(self.data_dict.keys())
                np.random.shuffle(tickers)

                for ticker in tickers:
                    if ticker in self.inventory: continue

                    df = self.data_dict[ticker]
                    if current_date not in df.index: continue
                    row = df.loc[current_date]

                    if row['Signal_Buy_Filter']:
                        # Buy State 直接使用 FEATURE_COLS
                        state = row[FEATURE_COLS].values.astype(np.float32)
                        action, _ = self.buy_model.predict(state, deterministic=True)

                        if action == 1:
                            target_amt = total_asset * self.position_size_pct
                            invest_amt = min(target_amt, self.cash)
                            if invest_amt > row['Close'] * 1000:
                                shares = int(invest_amt / row['Close'])
                                cost = shares * row['Close'] * (1 + 0.001425)
                                self.cash -= cost
                                self.inventory[ticker] = {
                                    'shares': shares,
                                    'cost_price': row['Close'],
                                    'days_held': 0
                                }
                                if len(self.inventory) >= self.max_positions: break

            # 3. 詳細紀錄
            # 重新計算收盤後的權益
            daily_equity = 0
            held_stocks = []
            for t, info in self.inventory.items():
                if current_date in self.data_dict[t].index:
                    val = info['shares'] * self.data_dict[t].loc[current_date]['Close']
                else:
                    val = info['shares'] * info['cost_price']
                daily_equity += val
                held_stocks.append(t)

            records.append({
                'Date': current_date,
                'Total_Value': self.cash + daily_equity,
                'Cash': self.cash,
                'Invested_Amount': daily_equity, # 實際投入股市的金額
                'Holdings_Count': len(held_stocks), # 持股檔數
                'Holdings_List': held_stocks # 持股名單
            })

        return pd.DataFrame(records).set_index('Date')

# --- 執行分析 ---
# 確保排除指數資料
stock_data_only = {k: v for k, v in processed_data.items() if k != "^TWII" and k != "0050.TW"}
analyzer = DetailedBacktester(stock_data_only, loaded_buy_model, loaded_sell_model)
daily_stats = analyzer.run()

# --- 年度統計 ---
daily_stats['Year'] = daily_stats.index.year
annual_stats = daily_stats.groupby('Year').agg({
    'Invested_Amount': 'mean',
    'Cash': 'mean',
    'Holdings_Count': 'mean',
    'Total_Value': 'last'
})

# --- 視覺化繪圖 ---
fig, ax1 = plt.subplots(figsize=(14, 7))

# 1. 資金配置堆疊圖 (柱狀圖)
years = annual_stats.index.astype(str)
p1 = ax1.bar(years, annual_stats['Invested_Amount'], label='Avg Invested Amount (Stock)', color='#ff9999', alpha=0.9)
p2 = ax1.bar(years, annual_stats['Cash'], bottom=annual_stats['Invested_Amount'], label='Avg Cash (Idle)', color='#66b3ff', alpha=0.5)

ax1.set_xlabel('Year', fontsize=12)
ax1.set_ylabel('Asset Value (TWD)', color='black', fontsize=12)
ax1.set_title('Annual AI Portfolio Status: Investment & Holdings', fontsize=16)
ax1.legend(loc='upper left', title='Asset Allocation')
ax1.grid(axis='y', alpha=0.3)

# 2. 持股數量趨勢 (折線圖 - 雙座標軸)
ax2 = ax1.twinx()
ax2.plot(years, annual_stats['Holdings_Count'], color='green', marker='D', linewidth=3, label='Avg Holdings Count')
ax2.set_ylabel('Number of Stocks Held', color='green', fontsize=12)
ax2.tick_params(axis='y', labelcolor='green')
ax2.set_ylim(0, 12) # 設定上限比較好觀察 (最多10檔)
ax2.legend(loc='upper right')

plt.tight_layout()
plt.savefig(os.path.join(RESULTS_PATH, "annual_holdings_analysis.png"))
plt.show()

# --- 文字報告輸出 ---
print("\n=== 年度 AI 持股與資金報告 ===")
for year in annual_stats.index:
    year_data = daily_stats[daily_stats['Year'] == year]

    # 統計熱門持股
    all_holdings = [t for sublist in year_data['Holdings_List'] for t in sublist]

    invested = annual_stats.loc[year, 'Invested_Amount']
    cash = annual_stats.loc[year, 'Cash']
    count = annual_stats.loc[year, 'Holdings_Count']
    utilization = (invested / (invested + cash)) * 100 # 資金利用率

    print(f"\n年份: {year}")
    print(f"  ● 平均投入金額: ${invested:,.0f} (資金利用率: {utilization:.1f}%)")
    print(f"  ● 平均持股檔數: {count:.1f} 檔")

    if all_holdings:
        top3 = Counter(all_holdings).most_common(3)
        print(f"  ● AI 最愛持股 (持有天數): ", end="")
        print(", ".join([f"{t}({d}天)" for t, d in top3]))
    else:
        print("  ● 本年度無持股 (AI 選擇空手)")